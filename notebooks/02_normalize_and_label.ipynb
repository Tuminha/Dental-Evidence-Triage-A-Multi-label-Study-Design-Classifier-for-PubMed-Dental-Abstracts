{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Normalize and Label\n",
        "\n",
        "## Goal\n",
        "\n",
        "Normalize MEDLINE XML â†’ flat rows with `pmid`, `title`, `abstract`, `journal`, `year`, `pub_types[]`, `mesh_terms[]`. Then map PT/keywords â†’ `labels[]`. We keep it multi-label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Step Matters\n",
        "\n",
        "Raw XML is unusable for ML. We need:\n",
        "\n",
        "- **Flat structure:** One row per paper\n",
        "- **Clean text:** Title + abstract concatenated\n",
        "- **Structured metadata:** Publication Types and MeSH terms as lists\n",
        "- **Canonical labels:** Map messy PT to clean categories\n",
        "\n",
        "This is where **data quality** is won or lost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Import libraries\n",
        "# Hint: import pandas as pd, yaml\n",
        "# from pathlib import Path\n",
        "# from lxml import etree\n",
        "# from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Collect raw XML paths\n",
        "# Hint: xml_files = sorted(Path('../data/raw').glob('*.xml'))\n",
        "#       print(f\"Found {len(xml_files)} XML files\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parse One Article\n",
        "\n",
        "XPath expressions to extract key fields:\n",
        "\n",
        "- `PMID`: `.//MedlineCitation/PMID/text()`\n",
        "- `Title`: `.//ArticleTitle//text()`\n",
        "- `Abstract`: `.//AbstractText//text()`\n",
        "- `Journal`: `.//Journal/Title/text()`\n",
        "- `Year`: `.//PubDate/Year/text()`\n",
        "- `Publication Types`: `.//PublicationType/text()`\n",
        "- `MeSH Terms`: `.//MeshHeading/DescriptorName/text()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Parse one article element\n",
        "# Hint: def parse_article(article_elem):\n",
        "#     pmid = article_elem.xpath('.//MedlineCitation/PMID/text()')\n",
        "#     title = ''.join(article_elem.xpath('.//ArticleTitle//text()'))\n",
        "#     abstract = ' '.join(article_elem.xpath('.//AbstractText//text()'))\n",
        "#     journal = ''.join(article_elem.xpath('.//Journal/Title/text()'))\n",
        "#     year_list = article_elem.xpath('.//PubDate/Year/text()')\n",
        "#     year = int(year_list[0]) if year_list else None\n",
        "#     pub_types = article_elem.xpath('.//PublicationType/text()')\n",
        "#     mesh_terms = article_elem.xpath('.//MeshHeading/DescriptorName/text()')\n",
        "#     return {\n",
        "#         'pmid': pmid[0] if pmid else None,\n",
        "#         'title': title,\n",
        "#         'abstract': abstract,\n",
        "#         'journal': journal,\n",
        "#         'year': year,\n",
        "#         'pub_types': pub_types,\n",
        "#         'mesh_terms': mesh_terms\n",
        "#     }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Build rows list â†’ DataFrame\n",
        "# Hint: rows = []\n",
        "# for xml_file in tqdm(xml_files):\n",
        "#     tree = etree.parse(str(xml_file))\n",
        "#     for article in tree.xpath('//PubmedArticle'):\n",
        "#         row = parse_article(article)\n",
        "#         if row['abstract']:  # Filter out papers without abstracts\n",
        "#             rows.append(row)\n",
        "# df = pd.DataFrame(rows)\n",
        "# print(f\"Parsed {len(df)} articles with abstracts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Save interim parquet\n",
        "# Hint: Path('../data/interim').mkdir(parents=True, exist_ok=True)\n",
        "#       df.to_parquet('../data/interim/normalized.parquet', index=False)\n",
        "#       print(\"Saved normalized.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label Design\n",
        "\n",
        "We define **10 canonical labels** for study design:\n",
        "\n",
        "1. **SystematicReview** â€” Systematic reviews\n",
        "2. **MetaAnalysis** â€” Meta-analyses (quantitative synthesis)\n",
        "3. **RCT** â€” Randomized Controlled Trials\n",
        "4. **ClinicalTrial** â€” Non-randomized clinical trials\n",
        "5. **Cohort** â€” Cohort studies (prospective/retrospective)\n",
        "6. **CaseControl** â€” Case-control studies\n",
        "7. **CaseReport** â€” Case reports / case series\n",
        "8. **InVitro** â€” In vitro or ex vivo laboratory studies\n",
        "9. **Animal** â€” Animal studies\n",
        "10. **Human** â€” Human subjects (not mutually exclusive)\n",
        "\n",
        "### Why Multi-label?\n",
        "\n",
        "- A paper can be **both RCT and Human**\n",
        "- Systematic reviews may also be **MetaAnalysis**\n",
        "- Some studies combine **Animal and InVitro** work\n",
        "\n",
        "### Mapping Strategy\n",
        "\n",
        "1. **Primary:** Match Publication Types (PT) from MEDLINE\n",
        "2. **Backfill:** Use keywords in title/abstract for InVitro/Animal/Human when PT missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load pt_to_labels.yaml\n",
        "# Hint: with open('../configs/pt_to_labels.yaml') as f:\n",
        "#     label_map = yaml.safe_load(f)\n",
        "# print(label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Map pub_types â†’ labels\n",
        "# Hint: def assign_labels(row, label_map):\n",
        "#     labels = set()\n",
        "#     text = (row['title'] + ' ' + row['abstract']).lower()\n",
        "#     \n",
        "#     # Match Publication Types\n",
        "#     for label_name, config in label_map.items():\n",
        "#         pt_list = config.get('pt', [])\n",
        "#         for pt in pt_list:\n",
        "#             if pt in row['pub_types']:\n",
        "#                 labels.add(label_name)\n",
        "#                 break\n",
        "#         \n",
        "#         # Keyword backfill\n",
        "#         keywords = config.get('keywords', [])\n",
        "#         for keyword in keywords:\n",
        "#             if keyword.lower() in text:\n",
        "#                 labels.add(label_name)\n",
        "#                 break\n",
        "#     \n",
        "#     return list(labels)\n",
        "#\n",
        "# df['labels'] = df.apply(lambda row: assign_labels(row, label_map), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Filter unlabeled rows\n",
        "# Hint: df['label_count'] = df['labels'].apply(len)\n",
        "#       print(f\"Papers with labels: {(df['label_count'] > 0).sum()} / {len(df)}\")\n",
        "#       df_labeled = df[df['label_count'] > 0].copy()\n",
        "#       print(f\"Keeping {len(df_labeled)} labeled papers ({len(df_labeled)/len(df)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Save labeled parquet\n",
        "# Hint: Path('../data/processed').mkdir(parents=True, exist_ok=True)\n",
        "#       df_labeled.to_parquet('../data/processed/dental_abstracts.parquet', index=False)\n",
        "#       print(\"Saved dental_abstracts.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendations\n",
        "\n",
        "Before moving forward:\n",
        "\n",
        "- **Keep examples** of ambiguous rows (e.g., both RCT and ClinicalTrial)\n",
        "- **Track label cardinality:** What's the average number of labels per paper?\n",
        "- **Note class imbalance:** Some labels will be much rarer than others\n",
        "- **Spot-check:** Manually review 10-20 random papers to validate labeling logic\n",
        "\n",
        "### Quick Stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Label cardinality stats\n",
        "# Hint: print(f\"Average labels per paper: {df_labeled['label_count'].mean():.2f}\")\n",
        "#       print(f\"Max labels: {df_labeled['label_count'].max()}\")\n",
        "#       # Show distribution\n",
        "#       print(\"\\nLabel count distribution:\")\n",
        "#       print(df_labeled['label_count'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§˜ Reflection Log\n",
        "\n",
        "**What did you learn in this session?**\n",
        "- \n",
        "\n",
        "**What challenges did you encounter?**\n",
        "- \n",
        "\n",
        "**How will this improve Periospot AI?**\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
