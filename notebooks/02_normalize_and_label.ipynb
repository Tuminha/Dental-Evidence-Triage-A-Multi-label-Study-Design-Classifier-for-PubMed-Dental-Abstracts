{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Normalize and Label\n",
        "\n",
        "## Goal\n",
        "\n",
        "Normalize MEDLINE XML â†’ flat rows with `pmid`, `title`, `abstract`, `journal`, `year`, `pub_types[]`, `mesh_terms[]`. Then map PT/keywords â†’ `labels[]`. We keep it multi-label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Step Matters\n",
        "\n",
        "Raw XML is unusable for ML. We need:\n",
        "\n",
        "- **Flat structure:** One row per paper\n",
        "- **Clean text:** Title + abstract concatenated\n",
        "- **Structured metadata:** Publication Types and MeSH terms as lists\n",
        "- **Canonical labels:** Map messy PT to clean categories\n",
        "\n",
        "This is where **data quality** is won or lost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Import libraries for XML parsing and DataFrame operations.\n",
        "# Hints:\n",
        "# 1) You'll need pandas, yaml, Path, lxml.etree, tqdm\n",
        "# Acceptance:\n",
        "# - All imports successful\n",
        "# - Can call etree.parse() and pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Find all downloaded XML files.\n",
        "# Hints:\n",
        "# 1) Use Path.glob() to find *.xml in ../data/raw\n",
        "# 2) Sort for reproducible ordering\n",
        "# Acceptance:\n",
        "# - List of Path objects for all XML files\n",
        "# - Print count\n",
        "\n",
        "# TODO: collect xml_files from ../data/raw\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parse One Article\n",
        "\n",
        "XPath expressions to extract key fields:\n",
        "\n",
        "- `PMID`: `.//MedlineCitation/PMID/text()`\n",
        "- `Title`: `.//ArticleTitle//text()`\n",
        "- `Abstract`: `.//AbstractText//text()`\n",
        "- `Journal`: `.//Journal/Title/text()`\n",
        "- `Year`: `.//PubDate/Year/text()`\n",
        "- `Publication Types`: `.//PublicationType/text()`\n",
        "- `MeSH Terms`: `.//MeshHeading/DescriptorName/text()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Extract key fields from one PubmedArticle XML node.\n",
        "# Hints:\n",
        "# 1) Use XPath to navigate (see docs for paths above)\n",
        "# 2) Return dict with 7 fields: pmid, title, abstract, journal, year, pub_types, mesh_terms\n",
        "# 3) Join text nodes; handle missing values gracefully\n",
        "# Acceptance:\n",
        "# - Function parse_article(article_elem) -> dict\n",
        "# - pub_types and mesh_terms are lists\n",
        "# - year is int or None\n",
        "\n",
        "def parse_article(article_elem):\n",
        "    \"\"\"Extract minimal fields from MEDLINE XML node.\"\"\"\n",
        "    # TODO: implement XPath extraction for all fields\n",
        "    raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Parse all XML files into a DataFrame.\n",
        "# Hints:\n",
        "# 1) Loop through xml_files with tqdm for progress\n",
        "# 2) Parse each file, extract all PubmedArticle nodes\n",
        "# 3) Filter out rows with empty abstracts\n",
        "# 4) Create DataFrame from list of dicts\n",
        "# Acceptance:\n",
        "# - DataFrame with columns: pmid, title, abstract, journal, year, pub_types, mesh_terms\n",
        "# - Only papers with abstracts included\n",
        "# - Print final count\n",
        "\n",
        "# TODO: build DataFrame from all XML files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Save normalized DataFrame as parquet.\n",
        "# Hints:\n",
        "# 1) Create ../data/interim directory if needed\n",
        "# 2) Use df.to_parquet() without index\n",
        "# Acceptance:\n",
        "# - File ../data/interim/normalized.parquet exists\n",
        "# - Can reload with pd.read_parquet()\n",
        "\n",
        "# TODO: save normalized DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label Design\n",
        "\n",
        "We define **10 canonical labels** for study design:\n",
        "\n",
        "1. **SystematicReview** â€” Systematic reviews\n",
        "2. **MetaAnalysis** â€” Meta-analyses (quantitative synthesis)\n",
        "3. **RCT** â€” Randomized Controlled Trials\n",
        "4. **ClinicalTrial** â€” Non-randomized clinical trials\n",
        "5. **Cohort** â€” Cohort studies (prospective/retrospective)\n",
        "6. **CaseControl** â€” Case-control studies\n",
        "7. **CaseReport** â€” Case reports / case series\n",
        "8. **InVitro** â€” In vitro or ex vivo laboratory studies\n",
        "9. **Animal** â€” Animal studies\n",
        "10. **Human** â€” Human subjects (not mutually exclusive)\n",
        "\n",
        "### Why Multi-label?\n",
        "\n",
        "- A paper can be **both RCT and Human**\n",
        "- Systematic reviews may also be **MetaAnalysis**\n",
        "- Some studies combine **Animal and InVitro** work\n",
        "\n",
        "### Mapping Strategy\n",
        "\n",
        "1. **Primary:** Match Publication Types (PT) from MEDLINE\n",
        "2. **Backfill:** Use keywords in title/abstract for InVitro/Animal/Human when PT missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Load Publication Type â†’ label mapping.\n",
        "# Hints:\n",
        "# 1) Use yaml.safe_load() on ../configs/pt_to_labels.yaml\n",
        "# 2) Returns nested dict: label_name -> {pt: [...], keywords: [...]}\n",
        "# Acceptance:\n",
        "# - label_map dict has 10 keys (one per label)\n",
        "# - Print to inspect structure\n",
        "\n",
        "# TODO: load label_map from config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Assign canonical labels based on Publication Types and keywords.\n",
        "# Hints:\n",
        "# 1) For each row, check if PT matches any in label_map\n",
        "# 2) Also check keywords in title+abstract (case-insensitive)\n",
        "# 3) Return list of matched labels (multi-label)\n",
        "# 4) Apply function to create 'labels' column\n",
        "# Acceptance:\n",
        "# - Function assign_labels(row, label_map) -> list[str]\n",
        "# - Multi-label: paper can have multiple labels\n",
        "# - New column df['labels'] exists\n",
        "\n",
        "def assign_labels(row, label_map):\n",
        "    \"\"\"Map Publication Types/keywords to canonical labels.\"\"\"\n",
        "    # TODO: iterate label_map, check PT and keyword matches\n",
        "    raise NotImplementedError\n",
        "\n",
        "# TODO: apply assign_labels to create df['labels'] column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Filter out papers without labels.\n",
        "# Hints:\n",
        "# 1) Create helper column 'label_count' = length of labels list\n",
        "# 2) Keep only rows with label_count > 0\n",
        "# 3) Print before/after counts and percentage kept\n",
        "# Acceptance:\n",
        "# - df_labeled has only papers with at least one label\n",
        "# - Shows coverage percentage\n",
        "\n",
        "# TODO: filter and create df_labeled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Save labeled data as parquet.\n",
        "# Hints:\n",
        "# 1) Create ../data/processed directory\n",
        "# 2) Save df_labeled to dental_abstracts.parquet\n",
        "# Acceptance:\n",
        "# - File exists and can be reloaded\n",
        "# - Contains labels column\n",
        "\n",
        "# TODO: save df_labeled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendations\n",
        "\n",
        "Before moving forward:\n",
        "\n",
        "- **Keep examples** of ambiguous rows (e.g., both RCT and ClinicalTrial)\n",
        "- **Track label cardinality:** What's the average number of labels per paper?\n",
        "- **Note class imbalance:** Some labels will be much rarer than others\n",
        "- **Spot-check:** Manually review 10-20 random papers to validate labeling logic\n",
        "\n",
        "### Quick Stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Compute and display label cardinality statistics.\n",
        "# Hints:\n",
        "# 1) Calculate mean and max of label_count\n",
        "# 2) Show value_counts distribution (how many papers have 1, 2, 3... labels)\n",
        "# Acceptance:\n",
        "# - Prints avg labels per paper\n",
        "# - Prints max labels\n",
        "# - Shows distribution table\n",
        "\n",
        "# TODO: compute and print label cardinality stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§˜ Reflection Log\n",
        "\n",
        "**What did you learn in this session?**\n",
        "- \n",
        "\n",
        "**What challenges did you encounter?**\n",
        "- \n",
        "\n",
        "**How will this improve Periospot AI?**\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
