{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 - Push to Hugging Face Hub\n",
        "\n",
        "## Goal\n",
        "\n",
        "Publish: push the model to the Hugging Face Hub with a model card, and (optionally) push a small sample dataset. Then add an inference widget.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Import libraries\n",
        "# Hint: import os\n",
        "# from pathlib import Path\n",
        "# from huggingface_hub import login, HfApi, create_repo, upload_folder\n",
        "# import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Login & Setup\n",
        "\n",
        "Set `HUGGINGFACE_HUB_TOKEN` in your environment or pass it here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Login & repo names\n",
        "# Hint: token = os.getenv('HUGGINGFACE_HUB_TOKEN')\n",
        "#       if token:\n",
        "#           login(token=token)\n",
        "#           print(\"‚úÖ Logged in to Hugging Face Hub\")\n",
        "#       else:\n",
        "#           print(\"‚ö†Ô∏è No HF token found; call login() interactively if needed\")\n",
        "# \n",
        "# MODEL_REPO = \"Tuminha/dental-evidence-triage\"\n",
        "# DATASET_REPO = \"Tuminha/dental-evidence-triage-sample\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Model Card\n",
        "\n",
        "Load the template and fill in your actual metrics from notebook 05.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Prepare model card text\n",
        "# Hint: model_card_template = Path('../MODEL_CARD_TEMPLATE.md').read_text()\n",
        "# \n",
        "# # Replace placeholders with actual metrics (example)\n",
        "# model_card = model_card_template.replace('[TARGET: ‚â•0.75]', '0.78')  # your actual micro-F1\n",
        "# model_card = model_card.replace('[TBD]', '0.XX')  # fill in other metrics\n",
        "# \n",
        "# # Write to model directory\n",
        "# Path('../artifacts/model/best/README.md').write_text(model_card)\n",
        "# print(\"‚úÖ Model card written to ../artifacts/model/best/README.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push Model to Hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Push folder\n",
        "# Hint: api = HfApi()\n",
        "# \n",
        "# # Create repo if it doesn't exist\n",
        "# try:\n",
        "#     create_repo(repo_id=MODEL_REPO, repo_type=\"model\", exist_ok=True)\n",
        "#     print(f\"‚úÖ Created/verified repo: {MODEL_REPO}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"‚ö†Ô∏è Repo creation: {e}\")\n",
        "# \n",
        "# # Upload\n",
        "# api.upload_folder(\n",
        "#     repo_id=MODEL_REPO,\n",
        "#     folder_path='../artifacts/model/best',\n",
        "#     repo_type=\"model\"\n",
        "# )\n",
        "# print(f\"‚úÖ Model pushed to https://huggingface.co/{MODEL_REPO}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Push Sample Dataset\n",
        "\n",
        "Push a small sample (2-5k rows) for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: (Optional) push sample dataset\n",
        "# Hint: # Load and sample\n",
        "# train_df = pd.read_parquet('../data/processed/train.parquet')\n",
        "# sample_df = train_df.sample(n=min(2000, len(train_df)), random_state=42)\n",
        "# sample_df['text'] = sample_df['title'] + ' ' + sample_df['abstract']\n",
        "# sample_df = sample_df[['pmid', 'text', 'labels', 'year']]\n",
        "# \n",
        "# # Save locally\n",
        "# Path('../artifacts/dataset_sample').mkdir(parents=True, exist_ok=True)\n",
        "# sample_df.to_parquet('../artifacts/dataset_sample/train_sample.parquet', index=False)\n",
        "# \n",
        "# # Create dataset repo\n",
        "# try:\n",
        "#     create_repo(repo_id=DATASET_REPO, repo_type=\"dataset\", exist_ok=True)\n",
        "#     print(f\"‚úÖ Created/verified repo: {DATASET_REPO}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"‚ö†Ô∏è Dataset repo: {e}\")\n",
        "# \n",
        "# # Upload\n",
        "# api.upload_folder(\n",
        "#     repo_id=DATASET_REPO,\n",
        "#     folder_path='../artifacts/dataset_sample',\n",
        "#     repo_type=\"dataset\"\n",
        "# )\n",
        "# print(f\"‚úÖ Dataset pushed to https://huggingface.co/datasets/{DATASET_REPO}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Inference Widget\n",
        "\n",
        "1. Go to https://huggingface.co/Tuminha/dental-evidence-triage\n",
        "2. Settings ‚Üí Model Card ‚Üí Add example inputs\n",
        "3. Example:\n",
        "\n",
        "```\n",
        "Title: Effect of chlorhexidine on dental implants: a randomized controlled trial. \n",
        "Abstract: This study evaluated the efficacy of chlorhexidine mouthrinse in preventing peri-implantitis. Sixty patients with dental implants were randomly assigned...\n",
        "```\n",
        "\n",
        "Expected labels: `[RCT, Human]`\n",
        "\n",
        "## Recommendations\n",
        "\n",
        "- **Enable the inference widget** in model settings\n",
        "- **Add label list and examples** to the model card\n",
        "- **Test the widget** with 3-5 diverse abstracts\n",
        "\n",
        "## üßò Reflection Log\n",
        "\n",
        "**What did you learn in this session?**\n",
        "- \n",
        "\n",
        "**What challenges did you encounter?**\n",
        "- \n",
        "\n",
        "**How will this improve Periospot AI?**\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
