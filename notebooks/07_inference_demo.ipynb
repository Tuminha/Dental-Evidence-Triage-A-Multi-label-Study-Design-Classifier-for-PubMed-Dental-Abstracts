{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07 - Inference Demo\n",
        "\n",
        "## Goal\n",
        "\n",
        "Try the model on real abstracts: paste text or a PubMed URL; show predicted labels with probabilities. We'll also add a tiny Gradio block.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Import libraries for inference demo.\n",
        "# Hints:\n",
        "# 1) transformers, torch, gradio\n",
        "# 2) src.utils (eutils_get)\n",
        "# 3) lxml.etree for PubMed parsing\n",
        "# Acceptance:\n",
        "# - All imports successful\n",
        "\n",
        "# TODO: import libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
        "from src.utils import eutils_get\n",
        "import lxml.etree\n",
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Define LABELS (same order as training!).\n",
        "# Acceptance:\n",
        "# - LABELS list with all 10 categories\n",
        "\n",
        "# TODO: define LABELS\n",
        "LABELS = [\n",
        "    'SystematicReview',  # 1. Systematic reviews\n",
        "    'MetaAnalysis',      # 2. Meta-analyses (quantitative synthesis)\n",
        "    'RCT',               # 3. Randomized Controlled Trials\n",
        "    'ClinicalTrial',     # 4. Non-randomized clinical trials\n",
        "    'Cohort',            # 5. Cohort studies (prospective/retrospective)\n",
        "    'CaseControl',       # 6. Case-control studies\n",
        "    'CaseReport',        # 7. Case reports / case series\n",
        "    'InVitro',           # 8. In vitro or ex vivo laboratory studies\n",
        "    'Animal',            # 9. Animal studies\n",
        "    'Human'              # 10. Human subjects (not mutually exclusive)\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load from Hub\n",
        "\n",
        "Load the model directly from Hugging Face (or local path if not yet pushed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded from: Tuminha/dental-evidence-triage\n",
            "‚úÖ Device: cpu (using CPU for stability)\n",
            "‚úÖ Model ready for inference\n"
          ]
        }
      ],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Load model and tokenizer from Hugging Face Hub (or local).\n",
        "# Hints:\n",
        "# 1) Use \"Tuminha/dental-evidence-triage\" or \"../artifacts/model/best\"\n",
        "# 2) Set model to eval mode\n",
        "# Acceptance:\n",
        "# - tokenizer and model loaded\n",
        "# - Ready for inference\n",
        "\n",
        "# TODO: load model\n",
        "# Load from HF Hub (or use \"../artifacts/model/best\" for local)\n",
        "hf_path = \"Tuminha/dental-evidence-triage\"\n",
        "# Alternative: hf_path = \"../artifacts/model/best\"  # Use this if model not yet on HF\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(hf_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(hf_path)\n",
        "\n",
        "# Use CPU for inference (more reliable than MPS for Hugging Face models)\n",
        "# MPS can have issues with certain operations, CPU is more stable\n",
        "device = torch.device(\"cpu\")\n",
        "# Alternative: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Note: MPS (Apple Silicon) can cause \"Placeholder storage\" errors, so we use CPU\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(f\"‚úÖ Model loaded from: {hf_path}\")\n",
        "print(f\"‚úÖ Device: {device} (using CPU for stability)\")\n",
        "print(f\"‚úÖ Model ready for inference\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility: Fetch PubMed Abstract by PMID\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Loading protocols for single-implant crowns: a systematic review and meta-analysis.\n",
            "Abstract: To test whether or not immediate loading of single-implant crowns renders different results from ear...\n",
            "Publication Types (from PubMed): ['Journal Article', 'Meta-Analysis', \"Research Support, Non-U.S. Gov't\", 'Systematic Review']\n",
            "MeSH Terms (from PubMed): ['Female', 'Humans', 'Middle Aged']...\n",
            "\n",
            "‚ö†Ô∏è  Note: These are raw metadata from PubMed.\n",
            "   True labels come from our dataset files (created in Notebook 02).\n"
          ]
        }
      ],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Utility to fetch abstract from PubMed by PMID.\n",
        "# Hints:\n",
        "# 1) Use eutils_get with efetch.fcgi\n",
        "# 2) Parse XML with lxml.etree\n",
        "# 3) Extract title and abstract, return as tuple\n",
        "# Acceptance:\n",
        "# - Function fetch_abstract_by_pmid(pmid) -> (title, abstract)\n",
        "# - Returns strings\n",
        "\n",
        "def fetch_abstract_by_pmid(pmid):\n",
        "    \"\"\"Fetch abstract text and metadata from PubMed by PMID.\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (title, abstract, pub_types, mesh_terms)\n",
        "        - title: Article title\n",
        "        - abstract: Abstract text\n",
        "        - pub_types: List of Publication Types from PubMed\n",
        "        - mesh_terms: List of MeSH terms from PubMed\n",
        "    \"\"\"\n",
        "    # Prepare parameters for efetch\n",
        "    params = {\n",
        "        'db': 'pubmed',\n",
        "        'id': str(pmid),\n",
        "        'retmode': 'xml',\n",
        "        'rettype': 'medline'\n",
        "    }\n",
        "    \n",
        "    # Call eutils_get - returns requests.Response object\n",
        "    response = eutils_get('efetch.fcgi', params)\n",
        "    \n",
        "    # Parse XML from response text\n",
        "    root = lxml.etree.fromstring(response.text.encode('utf-8'))\n",
        "    \n",
        "    # Extract title (handle None case)\n",
        "    title_elem = root.find('.//ArticleTitle')\n",
        "    title = title_elem.text if title_elem is not None and title_elem.text else \"\"\n",
        "    \n",
        "    # Extract abstract (handle None case and multiple AbstractText elements)\n",
        "    abstract_elem = root.find('.//AbstractText')\n",
        "    if abstract_elem is not None:\n",
        "        # AbstractText can have text directly or nested elements\n",
        "        if abstract_elem.text:\n",
        "            abstract = abstract_elem.text\n",
        "        else:\n",
        "            # If no direct text, get all text content from nested elements\n",
        "            abstract = ''.join(abstract_elem.itertext())\n",
        "    else:\n",
        "        abstract = \"\"\n",
        "    \n",
        "    # Extract Publication Types (what PubMed provides - NOT our labels!)\n",
        "    pub_types = root.xpath('.//PublicationType/text()')\n",
        "    \n",
        "    # Extract MeSH terms (what PubMed provides - NOT our labels!)\n",
        "    mesh_terms = root.xpath('.//MeshHeading/DescriptorName/text()')\n",
        "    \n",
        "    return title, abstract, pub_types, mesh_terms\n",
        "\n",
        "# Test with a real PMID (remove test with fake PMID)\n",
        "# Example: A real dental research paper\n",
        "title, abstract, pub_types, mesh_terms = fetch_abstract_by_pmid(\"24660200\")\n",
        "print(f\"Title: {title}\")\n",
        "print(f\"Abstract: {abstract[:100]}...\")\n",
        "print(f\"Publication Types (from PubMed): {pub_types}\")\n",
        "print(f\"MeSH Terms (from PubMed): {mesh_terms[:3]}...\")\n",
        "print(f\"\\n‚ö†Ô∏è  Note: These are raw metadata from PubMed.\")\n",
        "print(f\"   True labels come from our dataset files (created in Notebook 02).\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Function\n",
        "\n",
        "Returns top-k labels with probabilities, sorted descending.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Human', 0.9927734732627869), ('CaseControl', 0.009760159067809582), ('CaseReport', 0.0034319646656513214), ('Cohort', 0.002296593738719821), ('Animal', 0.0019579280633479357)]\n"
          ]
        }
      ],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Predict top-k labels for input text.\n",
        "# Hints:\n",
        "# 1) Tokenize, run through model, apply sigmoid\n",
        "# 2) Sort probabilities, return top-k (label, score) pairs\n",
        "# Acceptance:\n",
        "# - Function predict(text, top_k) -> list[(label, score)]\n",
        "# - Returns top predictions sorted by score\n",
        "\n",
        "def predict(text, top_k=5):\n",
        "    \"\"\"Predict study design labels for text.\"\"\"\n",
        "    # Truncate text to 2000 chars (same as training)\n",
        "    text = str(text)[:2000]\n",
        "    \n",
        "    # Tokenize\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "    \n",
        "    # Get device from model (works even if device variable not in scope)\n",
        "    device = next(model.parameters()).device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Run through model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "    \n",
        "    # Apply sigmoid to get probabilities\n",
        "    probs = torch.sigmoid(logits)[0]  # Get first (and only) batch item\n",
        "    \n",
        "    # Create list of (label, probability) pairs\n",
        "    label_probs = [(LABELS[i], float(probs[i])) for i in range(len(LABELS))]\n",
        "    \n",
        "    # Sort by probability (descending) and return top_k\n",
        "    label_probs.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    return label_probs[:top_k]\n",
        "\n",
        "# Test\n",
        "print(predict(\"To test whether or not immediate loading of single-implant crowns renders different results from early and conventional loading with respect to implant survival, marginal bone loss, stability of peri-implant soft tissue, esthetics, and patient satisfaction.\"))    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Known Abstracts\n",
        "\n",
        "Try 3-5 diverse examples:\n",
        "1. **Systematic Review** ‚Äî should predict `[SystematicReview, MetaAnalysis?]`\n",
        "2. **RCT** ‚Äî should predict `[RCT, Human]`\n",
        "3. **Case Report** ‚Äî should predict `[CaseReport, Human]`\n",
        "4. **In Vitro** ‚Äî should predict `[InVitro]`\n",
        "5. **Animal Study** ‚Äî should predict `[Animal]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TEST 1: PMID 24660200 (may not be in dataset)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Testing PMID: 24660200\n",
            "================================================================================\n",
            "\n",
            "üìÑ Title: Loading protocols for single-implant crowns: a systematic review and meta-analysis.\n",
            "üìù Abstract: To test whether or not immediate loading of single-implant crowns renders different results from early and conventional loading with respect to implant survival, marginal bone loss, stability of peri-...\n",
            "\n",
            "üìã PubMed Metadata (raw - NOT our labels):\n",
            "   Publication Types: ['Journal Article', 'Meta-Analysis', \"Research Support, Non-U.S. Gov't\", 'Systematic Review']\n",
            "   MeSH Terms: ['Female', 'Humans', 'Middle Aged', 'Alveolar Bone Loss', 'Bone Density']...\n",
            "   ‚ö†Ô∏è  Note: These are converted to canonical labels in Notebook 02\n",
            "\n",
            "‚ö†Ô∏è  Not found in our dataset\n",
            "   (Searched in: dental_abstracts.parquet, train.parquet, val.parquet, test.parquet)\n",
            "   Possible reasons:\n",
            "   - PMID from different time period (our dataset: 2018-2025)\n",
            "   - Article was filtered out during labeling (no matching labels)\n",
            "   - Article not in our dental query scope\n",
            "\n",
            "   Sample PMIDs from train split: ['34574718', '34574666', '34574506']\n",
            "\n",
            "ü§ñ Model Predictions (threshold=0.5):\n",
            "   Predicted Labels: ['MetaAnalysis', 'Human', 'SystematicReview']\n",
            "\n",
            "üìä Top Predictions with Probabilities:\n",
            "      MetaAnalysis        : 0.9633\n",
            "      Human               : 0.9606\n",
            "      SystematicReview    : 0.8585\n",
            "      CaseControl         : 0.0217\n",
            "      Animal              : 0.0079\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TEST 2: Using a PMID from your dataset\n",
            "================================================================================\n",
            "Using sample PMID from train split: 34574718\n",
            "\n",
            "================================================================================\n",
            "Testing PMID: 34574718\n",
            "================================================================================\n",
            "\n",
            "üìÑ Title: Stability of Class II Malocclusion Treatment with the Austro Repositioner Followed by Fixed Appliances in Brachyfacial Patients.\n",
            "üìù Abstract: One of the goals of functional-appliance devices is to modify the vertical growth pattern, solving several kinds of malocclusion. This study aimed to evaluate Class II malocclusion treatment's stabili...\n",
            "\n",
            "üìã PubMed Metadata (raw - NOT our labels):\n",
            "   Publication Types: ['Journal Article']\n",
            "   MeSH Terms: ['Cephalometry', 'Child', 'Female', 'Humans', 'Male']...\n",
            "   ‚ö†Ô∏è  Note: These are converted to canonical labels in Notebook 02\n",
            "\n",
            "‚úÖ Found in our dataset (original split)\n",
            "üè∑Ô∏è  True Labels (derived in Notebook 02): ['Human']\n",
            "   üìå These labels were created by mapping:\n",
            "      - Publication Types ‚Üí labels\n",
            "      - MeSH terms ‚Üí labels\n",
            "      - Keywords ‚Üí labels (fallback)\n",
            "\n",
            "ü§ñ Model Predictions (threshold=0.5):\n",
            "   Predicted Labels: ['Human']\n",
            "\n",
            "üìä Top Predictions with Probabilities:\n",
            "   ‚úÖ Human               : 0.9994\n",
            "   ‚ùå CaseControl         : 0.1148\n",
            "   ‚ùå Cohort              : 0.0851\n",
            "   ‚ùå RCT                 : 0.0231\n",
            "   ‚ùå ClinicalTrial       : 0.0166\n",
            "\n",
            "üìà Comparison:\n",
            "   ‚úÖ Correct: ['Human']\n",
            "\n",
            "   Precision: 100.00% (1/1)\n",
            "   Recall: 100.00% (1/1)\n",
            "   F1 Score: 100.00%\n",
            "\n",
            "================================================================================\n",
            "üìä ACCURACY ASSESSMENT\n",
            "================================================================================\n",
            "‚úÖ EXCELLENT! Model predicted perfectly!\n",
            "   All 1 true label(s) were correctly identified.\n",
            "   No false positives or false negatives.\n",
            "\n",
            "üìà Performance Summary:\n",
            "   üèÜ Outstanding performance (F1 ‚â• 0.90)\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "TEST 3: Additional Examples\n",
            "================================================================================\n",
            "To test with more PMIDs from your dataset, uncomment and modify:\n",
            "# df = pd.read_parquet('../data/processed/train.parquet')\n",
            "# test_with_pmid(df.iloc[5]['pmid'])  # Test with 6th article\n",
            "# test_with_pmid(df.iloc[10]['pmid'])  # Test with 11th article\n"
          ]
        }
      ],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: Test predict function on known examples.\n",
        "# Hints:\n",
        "# 1) Create dict with 5 diverse examples (SR, RCT, CaseReport, InVitro, Animal)\n",
        "# 2) For each, call predict() and print top-3 results\n",
        "# 3) Verify predictions match expected study designs\n",
        "# Acceptance:\n",
        "# - Tests 5 examples covering different label types\n",
        "# - Shows label : probability for each\n",
        "\n",
        "def get_true_labels_from_dataset(pmid):\n",
        "    \"\"\"Get true labels for a PMID from our processed dataset.\"\"\"\n",
        "    # Convert PMID to string for comparison\n",
        "    pmid_str = str(pmid)\n",
        "    processed_data_path = Path(\"../data/processed\")\n",
        "    \n",
        "    # First, try the original dataset file (before splits)\n",
        "    original_path = processed_data_path / \"dental_abstracts.parquet\"\n",
        "    if original_path.exists():\n",
        "        try:\n",
        "            df = pd.read_parquet(original_path)\n",
        "            # Try both string and integer comparison (PMID might be stored as either)\n",
        "            matching_rows = df[(df['pmid'] == pmid_str) | (df['pmid'].astype(str) == pmid_str)]\n",
        "            if len(matching_rows) > 0:\n",
        "                labels = matching_rows.iloc[0]['labels']\n",
        "                return labels, \"original\"\n",
        "        except Exception as e:\n",
        "            print(f\"   (Note: Could not check original dataset: {e})\")\n",
        "    \n",
        "    # Then try train, val, test splits\n",
        "    for split_name in ['train', 'val', 'test']:\n",
        "        split_path = processed_data_path / f\"{split_name}.parquet\"\n",
        "        if split_path.exists():\n",
        "            try:\n",
        "                df = pd.read_parquet(split_path)\n",
        "                # Try both string and integer comparison\n",
        "                matching_rows = df[(df['pmid'] == pmid_str) | (df['pmid'].astype(str) == pmid_str)]\n",
        "                if len(matching_rows) > 0:\n",
        "                    labels = matching_rows.iloc[0]['labels']\n",
        "                    return labels, split_name\n",
        "            except Exception as e:\n",
        "                continue  # Skip this split if there's an error\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "def test_with_pmid(pmid, threshold=0.5):\n",
        "    \"\"\"Test model predictions on a PMID and compare with true labels.\n",
        "    \n",
        "    Important: True labels come from our dataset files (created in Notebook 02),\n",
        "    NOT directly from PubMed. PubMed only provides Publication Types and MeSH terms,\n",
        "    which were converted to canonical labels in Notebook 02.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Testing PMID: {pmid}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # Fetch abstract and metadata from PubMed\n",
        "    try:\n",
        "        title, abstract, pub_types, mesh_terms = fetch_abstract_by_pmid(pmid)\n",
        "        print(f\"\\nüìÑ Title: {title}\")\n",
        "        print(f\"üìù Abstract: {abstract[:200]}...\" if len(abstract) > 200 else f\"üìù Abstract: {abstract}\")\n",
        "        \n",
        "        # Show what PubMed provides (raw metadata)\n",
        "        print(f\"\\nüìã PubMed Metadata (raw - NOT our labels):\")\n",
        "        print(f\"   Publication Types: {pub_types if pub_types else 'None'}\")\n",
        "        print(f\"   MeSH Terms: {mesh_terms[:5] if mesh_terms else 'None'}...\" if len(mesh_terms) > 5 else f\"   MeSH Terms: {mesh_terms if mesh_terms else 'None'}\")\n",
        "        print(f\"   ‚ö†Ô∏è  Note: These are converted to canonical labels in Notebook 02\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching abstract: {e}\")\n",
        "        return\n",
        "    \n",
        "    # Get true labels from our dataset (these were created in Notebook 02)\n",
        "    # The labels come from mapping Publication Types + MeSH terms ‚Üí canonical labels\n",
        "    true_labels, split_name = get_true_labels_from_dataset(pmid)\n",
        "    if true_labels:\n",
        "        print(f\"\\n‚úÖ Found in our dataset ({split_name} split)\")\n",
        "        print(f\"üè∑Ô∏è  True Labels (derived in Notebook 02): {true_labels}\")\n",
        "        print(f\"   üìå These labels were created by mapping:\")\n",
        "        print(f\"      - Publication Types ‚Üí labels\")\n",
        "        print(f\"      - MeSH terms ‚Üí labels\")\n",
        "        print(f\"      - Keywords ‚Üí labels (fallback)\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  Not found in our dataset\")\n",
        "        print(f\"   (Searched in: dental_abstracts.parquet, train.parquet, val.parquet, test.parquet)\")\n",
        "        print(f\"   Possible reasons:\")\n",
        "        print(f\"   - PMID from different time period (our dataset: 2018-2025)\")\n",
        "        print(f\"   - Article was filtered out during labeling (no matching labels)\")\n",
        "        print(f\"   - Article not in our dental query scope\")\n",
        "        # Optional: Show a sample of PMIDs from the dataset for debugging\n",
        "        try:\n",
        "            sample_path = Path(\"../data/processed/train.parquet\")\n",
        "            if sample_path.exists():\n",
        "                sample_df = pd.read_parquet(sample_path)\n",
        "                print(f\"\\n   Sample PMIDs from train split: {sample_df['pmid'].head(3).tolist()}\")\n",
        "        except:\n",
        "            pass\n",
        "        true_labels = []\n",
        "    \n",
        "    # Get predictions\n",
        "    text = f\"{title} {abstract}\"\n",
        "    predictions = predict(text, top_k=10)\n",
        "    \n",
        "    # Apply threshold to get binary predictions\n",
        "    predicted_labels = [label for label, prob in predictions if prob >= threshold]\n",
        "    \n",
        "    print(f\"\\nü§ñ Model Predictions (threshold={threshold}):\")\n",
        "    print(f\"   Predicted Labels: {predicted_labels}\")\n",
        "    print(f\"\\nüìä Top Predictions with Probabilities:\")\n",
        "    for label, prob in predictions[:5]:\n",
        "        marker = \"‚úÖ\" if label in true_labels else \"‚ùå\" if true_labels else \"  \"\n",
        "        print(f\"   {marker} {label:20s}: {prob:.4f}\")\n",
        "    \n",
        "    # Compare if we have true labels\n",
        "    if true_labels:\n",
        "        print(f\"\\nüìà Comparison:\")\n",
        "        correct = set(predicted_labels) & set(true_labels)\n",
        "        false_positives = set(predicted_labels) - set(true_labels)\n",
        "        false_negatives = set(true_labels) - set(predicted_labels)\n",
        "        \n",
        "        if correct:\n",
        "            print(f\"   ‚úÖ Correct: {sorted(correct)}\")\n",
        "        if false_positives:\n",
        "            print(f\"   ‚ùå False Positives: {sorted(false_positives)}\")\n",
        "        if false_negatives:\n",
        "            print(f\"   ‚ö†Ô∏è  False Negatives (missed): {sorted(false_negatives)}\")\n",
        "        \n",
        "        # Calculate simple accuracy metrics\n",
        "        if true_labels:\n",
        "            precision = len(correct) / len(predicted_labels) if predicted_labels else 0\n",
        "            recall = len(correct) / len(true_labels) if true_labels else 0\n",
        "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            \n",
        "            print(f\"\\n   Precision: {precision:.2%} ({len(correct)}/{len(predicted_labels)})\")\n",
        "            print(f\"   Recall: {recall:.2%} ({len(correct)}/{len(true_labels)})\")\n",
        "            print(f\"   F1 Score: {f1_score:.2%}\")\n",
        "            \n",
        "            # Overall accuracy assessment\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"üìä ACCURACY ASSESSMENT\")\n",
        "            print(f\"{'='*80}\")\n",
        "            \n",
        "            # Check if predictions match well\n",
        "            all_correct = (set(predicted_labels) == set(true_labels))\n",
        "            mostly_correct = len(correct) >= len(true_labels) * 0.8 and len(false_positives) <= 1\n",
        "            partially_correct = len(correct) > 0 and f1_score >= 0.5\n",
        "            \n",
        "            if all_correct:\n",
        "                print(f\"‚úÖ EXCELLENT! Model predicted perfectly!\")\n",
        "                print(f\"   All {len(true_labels)} true label(s) were correctly identified.\")\n",
        "                print(f\"   No false positives or false negatives.\")\n",
        "            elif mostly_correct:\n",
        "                print(f\"‚úÖ VERY GOOD! Model predicted accurately!\")\n",
        "                print(f\"   Correctly identified {len(correct)}/{len(true_labels)} true label(s).\")\n",
        "                if false_positives:\n",
        "                    print(f\"   Minor issue: {len(false_positives)} false positive(s): {sorted(false_positives)}\")\n",
        "                if false_negatives:\n",
        "                    print(f\"   Minor issue: {len(false_negatives)} missed label(s): {sorted(false_negatives)}\")\n",
        "            elif partially_correct:\n",
        "                print(f\"‚ö†Ô∏è  MODERATE: Model predicted partially correctly.\")\n",
        "                print(f\"   Correctly identified {len(correct)}/{len(true_labels)} true label(s).\")\n",
        "                if false_positives:\n",
        "                    print(f\"   ‚ö†Ô∏è  {len(false_positives)} false positive(s): {sorted(false_positives)}\")\n",
        "                if false_negatives:\n",
        "                    print(f\"   ‚ö†Ô∏è  {len(false_negatives)} missed label(s): {sorted(false_negatives)}\")\n",
        "            else:\n",
        "                print(f\"‚ùå POOR: Model predictions don't match well with true labels.\")\n",
        "                print(f\"   Only {len(correct)}/{len(true_labels)} true label(s) correctly identified.\")\n",
        "                if false_positives:\n",
        "                    print(f\"   ‚ùå {len(false_positives)} false positive(s): {sorted(false_positives)}\")\n",
        "                if false_negatives:\n",
        "                    print(f\"   ‚ùå {len(false_negatives)} missed label(s): {sorted(false_negatives)}\")\n",
        "            \n",
        "            # Additional feedback based on F1 score\n",
        "            print(f\"\\nüìà Performance Summary:\")\n",
        "            if f1_score >= 0.9:\n",
        "                print(f\"   üèÜ Outstanding performance (F1 ‚â• 0.90)\")\n",
        "            elif f1_score >= 0.7:\n",
        "                print(f\"   üëç Good performance (F1 ‚â• 0.70)\")\n",
        "            elif f1_score >= 0.5:\n",
        "                print(f\"   ‚ö†Ô∏è  Moderate performance (F1 ‚â• 0.50)\")\n",
        "            else:\n",
        "                print(f\"   ‚ùå Needs improvement (F1 < 0.50)\")\n",
        "            \n",
        "            print(f\"{'='*80}\")\n",
        "\n",
        "# Helper function to get a PMID from the dataset for testing\n",
        "def get_sample_pmid_from_dataset(split='train', index=0):\n",
        "    \"\"\"Get a sample PMID from the dataset for testing.\"\"\"\n",
        "    processed_data_path = Path(\"../data/processed\")\n",
        "    split_path = processed_data_path / f\"{split}.parquet\"\n",
        "    \n",
        "    if split_path.exists():\n",
        "        df = pd.read_parquet(split_path)\n",
        "        if len(df) > index:\n",
        "            return df.iloc[index]['pmid']\n",
        "    return None\n",
        "\n",
        "# Test with the PMID from Cell 8 (may not be in dataset)\n",
        "print(\"=\"*80)\n",
        "print(\"TEST 1: PMID 24660200 (may not be in dataset)\")\n",
        "print(\"=\"*80)\n",
        "test_with_pmid(\"24660200\")\n",
        "\n",
        "# Test with a PMID that IS in the dataset\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"TEST 2: Using a PMID from your dataset\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get a sample PMID from the train split\n",
        "sample_pmid = get_sample_pmid_from_dataset('train', 0)\n",
        "if sample_pmid:\n",
        "    print(f\"Using sample PMID from train split: {sample_pmid}\")\n",
        "    test_with_pmid(sample_pmid)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Could not find a sample PMID from the dataset\")\n",
        "\n",
        "# You can also test with specific PMIDs from your dataset\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"TEST 3: Additional Examples\")\n",
        "print(\"=\"*80)\n",
        "print(\"To test with more PMIDs from your dataset, uncomment and modify:\")\n",
        "print(\"# df = pd.read_parquet('../data/processed/train.parquet')\")\n",
        "print(\"# test_with_pmid(df.iloc[5]['pmid'])  # Test with 6th article\")\n",
        "print(\"# test_with_pmid(df.iloc[10]['pmid'])  # Test with 11th article\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradio Demo (Optional)\n",
        "\n",
        "Build a simple interface for interactive testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.49.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from gradio) (4.11.0)\n",
            "Collecting brotli>=1.1.0 (from gradio)\n",
            "  Downloading brotli-1.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (6.1 kB)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.121.2-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.13.3 (from gradio)\n",
            "  Downloading gradio_client-1.13.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (2.3.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from gradio) (2.11.10)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.14.4-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio) (4.15.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: fsspec in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from gradio-client==1.13.3->gradio) (2025.9.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
            "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: certifi in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/franciscoteixeirabarbosa/.local/lib/python3.11/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Downloading gradio-5.49.1-py3-none-any.whl (63.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.5/63.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.13.3-py3-none-any.whl (325 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.121.2-py3-none-any.whl (109 kB)\n",
            "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
            "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
            "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
            "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading brotli-1.2.0-cp311-cp311-macosx_10_9_universal2.whl (863 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m863.1/863.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading ruff-0.14.4-py3-none-macosx_11_0_arm64.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, brotli, uvicorn, tomlkit, shellingham, semantic-version, ruff, python-multipart, mdurl, groovy, ffmpy, annotated-doc, aiofiles, starlette, markdown-it-py, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21/21\u001b[0m [gradio]20/21\u001b[0m [gradio]client]]\n",
            "\u001b[1A\u001b[2KSuccessfully installed aiofiles-24.1.0 annotated-doc-0.0.4 brotli-1.2.0 fastapi-0.121.2 ffmpy-1.0.0 gradio-5.49.1 gradio-client-1.13.3 groovy-0.1.2 markdown-it-py-4.0.0 mdurl-0.1.2 pydub-0.25.1 python-multipart-0.0.20 rich-14.2.0 ruff-0.14.4 safehttpx-0.1.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.49.3 tomlkit-0.13.3 typer-0.20.0 uvicorn-0.38.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on public URL: https://5afec64398548b08b1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5afec64398548b08b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Goal: (Optional) Create interactive Gradio demo.\n",
        "import gradio as gr\n",
        "\n",
        "def gradio_predict(text):\n",
        "    \"\"\"Wrapper function for Gradio interface.\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Please enter some text.\"\n",
        "    \n",
        "    preds = predict(text, top_k=10)\n",
        "    output = \"\\n\".join([f\"{label}: {prob:.3f}\" for label, prob in preds])\n",
        "    return output\n",
        "\n",
        "# Create interface\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_predict,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Paste title + abstract here...\"),\n",
        "    outputs=gr.Textbox(label=\"Predicted Labels\", lines=15),\n",
        "    title=\"ü¶∑ Dental Evidence Triage\",\n",
        "    description=\"Classify dental research abstracts by study design.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendations\n",
        "\n",
        "- **Add 3-5 known abstracts** (one SR, one RCT, one CaseReport) as quick sanity checks\n",
        "- **Remind users:** assistive triage, not ground truth\n",
        "- **Test edge cases:** very short abstracts, non-English (should fail gracefully), missing abstract\n",
        "\n",
        "## üßò Reflection Log\n",
        "\n",
        "**What did you learn in this session?**\n",
        "- \n",
        "\n",
        "**What challenges did you encounter?**\n",
        "- \n",
        "\n",
        "**How will this improve Periospot AI?**\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
