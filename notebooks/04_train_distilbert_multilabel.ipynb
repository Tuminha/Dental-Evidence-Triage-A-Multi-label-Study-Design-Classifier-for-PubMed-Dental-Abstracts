{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Train DistilBERT Multi-label Classifier\n",
        "\n",
        "## Goal\n",
        "\n",
        "Train DistilBERT for multi-label classification on title+abstract. We'll use BCEWithLogits, monitor micro/macro F1, and tune threshold on the validation set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why Multi-label Classification?\n",
        "\n",
        "Each paper can have multiple study characteristics:\n",
        "- An **RCT** is also **Human**\n",
        "- A **Systematic Review** might be a **MetaAnalysis**\n",
        "- Some studies combine **Animal** + **InVitro**\n",
        "\n",
        "We use **binary cross-entropy** (BCE) for each label independently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Import libraries\n",
        "# Hint: import pandas as pd, numpy as np\n",
        "# from pathlib import Path\n",
        "# from datasets import Dataset\n",
        "# from transformers import (\n",
        "#     AutoTokenizer, AutoModelForSequenceClassification,\n",
        "#     TrainingArguments, Trainer\n",
        "# )\n",
        "# import evaluate\n",
        "# import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Define canonical labels (fixed order!)\n",
        "# Hint: LABELS = [\n",
        "#     'SystematicReview', 'MetaAnalysis', 'RCT', 'ClinicalTrial',\n",
        "#     'Cohort', 'CaseControl', 'CaseReport', 'InVitro', 'Animal', 'Human'\n",
        "# ]\n",
        "# NUM_LABELS = len(LABELS)\n",
        "# print(f\"Training for {NUM_LABELS} labels: {LABELS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Splits & Build HF Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load splits & build HF Datasets\n",
        "# Hint: train_df = pd.read_parquet('../data/processed/train.parquet')\n",
        "#       val_df = pd.read_parquet('../data/processed/val.parquet')\n",
        "#       test_df = pd.read_parquet('../data/processed/test.parquet')\n",
        "# \n",
        "# # Concatenate title + abstract; truncate to 2k chars\n",
        "# train_df['text'] = (train_df['title'] + ' ' + train_df['abstract']).str[:2000]\n",
        "# val_df['text'] = (val_df['title'] + ' ' + val_df['abstract']).str[:2000]\n",
        "# test_df['text'] = (test_df['title'] + ' ' + test_df['abstract']).str[:2000]\n",
        "# \n",
        "# print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Binarize Labels\n",
        "\n",
        "Convert list of labels â†’ multi-hot binary vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Binarize labels\n",
        "# Hint: def binarize_labels(labels_list):\n",
        "#     vec = np.zeros(NUM_LABELS, dtype=float)\n",
        "#     for label in labels_list:\n",
        "#         if label in LABELS:\n",
        "#             vec[LABELS.index(label)] = 1.0\n",
        "#     return vec.tolist()\n",
        "# \n",
        "# train_df['label_vec'] = train_df['labels'].apply(binarize_labels)\n",
        "# val_df['label_vec'] = val_df['labels'].apply(binarize_labels)\n",
        "# test_df['label_vec'] = test_df['labels'].apply(binarize_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Convert to HF Dataset\n",
        "# Hint: train_dataset = Dataset.from_pandas(train_df[['text', 'label_vec']])\n",
        "#       val_dataset = Dataset.from_pandas(val_df[['text', 'label_vec']])\n",
        "#       test_dataset = Dataset.from_pandas(test_df[['text', 'label_vec']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizer & Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Tokenizer & encoding\n",
        "# Hint: tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "# \n",
        "# def tokenize_function(examples):\n",
        "#     return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
        "# \n",
        "# train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "# val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "# test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "# \n",
        "# # Rename label_vec â†’ labels for Trainer\n",
        "# train_dataset = train_dataset.rename_column('label_vec', 'labels')\n",
        "# val_dataset = val_dataset.rename_column('label_vec', 'labels')\n",
        "# test_dataset = test_dataset.rename_column('label_vec', 'labels')\n",
        "# \n",
        "# train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "# val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "# test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Model init\n",
        "# Hint: model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     'distilbert-base-uncased',\n",
        "#     num_labels=NUM_LABELS,\n",
        "#     problem_type='multi_label_classification'\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Metrics function\n",
        "# Hint: from sklearn.metrics import precision_recall_fscore_support\n",
        "# \n",
        "# def compute_metrics(eval_pred):\n",
        "#     logits, labels = eval_pred\n",
        "#     probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "#     preds = (probs > 0.5).astype(int)\n",
        "#     \n",
        "#     precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "#         labels, preds, average='micro', zero_division=0\n",
        "#     )\n",
        "#     precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "#         labels, preds, average='macro', zero_division=0\n",
        "#     )\n",
        "#     \n",
        "#     return {\n",
        "#         'precision_micro': precision_micro,\n",
        "#         'recall_micro': recall_micro,\n",
        "#         'f1_micro': f1_micro,\n",
        "#         'precision_macro': precision_macro,\n",
        "#         'recall_macro': recall_macro,\n",
        "#         'f1_macro': f1_macro\n",
        "#     }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Arguments & Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: TrainingArguments\n",
        "# Hint: training_args = TrainingArguments(\n",
        "#     output_dir='../artifacts/model/checkpoints',\n",
        "#     eval_strategy='epoch',\n",
        "#     save_strategy='epoch',\n",
        "#     learning_rate=5e-5,\n",
        "#     per_device_train_batch_size=8,\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "#     warmup_ratio=0.1,\n",
        "#     logging_dir='../artifacts/logs',\n",
        "#     logging_steps=100,\n",
        "#     load_best_model_at_end=True,\n",
        "#     metric_for_best_model='f1_micro',\n",
        "#     greater_is_better=True,\n",
        "#     save_total_limit=2\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Train & save\n",
        "# Hint: trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     compute_metrics=compute_metrics\n",
        "# )\n",
        "# \n",
        "# trainer.train()\n",
        "# \n",
        "# # Save best model\n",
        "# Path('../artifacts/model/best').mkdir(parents=True, exist_ok=True)\n",
        "# trainer.save_model('../artifacts/model/best')\n",
        "# tokenizer.save_pretrained('../artifacts/model/best')\n",
        "# print(\"âœ… Model saved to ../artifacts/model/best\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendations\n",
        "\n",
        "- If rare labels underperform, try **class weights** or **focal loss** (stretch goal)\n",
        "- Track **ROC/PR curves** on val to tune per-label thresholds later\n",
        "- Monitor for **overfitting:** val metrics should not degrade while train improves\n",
        "\n",
        "## ðŸ§˜ Reflection Log\n",
        "\n",
        "**What did you learn in this session?**\n",
        "- \n",
        "\n",
        "**What challenges did you encounter?**\n",
        "- \n",
        "\n",
        "**How will this improve Periospot AI?**\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
